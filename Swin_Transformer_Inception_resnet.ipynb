{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6x6Qok5sV6_",
        "outputId": "facc6325-4433-46a2-897b-86339f21b59a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a2ZN1EEkseWT",
        "outputId": "00e6aa7c-43c9-4588-c00c-4688282cc86c"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c92Kj8esJd3",
        "outputId": "677f2117-bed7-49c1-f1fb-adbb8b04411b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import ViTConfig, ViTModel\n",
        "from timm import create_model\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "BATCH_SIZE = 16\n",
        "NUM_CLASSES = 2\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-4\n",
        "DATA_DIR = \"/content/drive/MyDrive/Pneumonia/\"\n",
        "\n",
        "# Data Transforms\n",
        "config = resolve_data_config({}, model=create_model('swin_base_patch4_window7_224', pretrained=True))\n",
        "transform_train = create_transform(**config)\n",
        "transform_val = create_transform(**config)\n",
        "\n",
        "# Datasets\n",
        "train_dataset = datasets.ImageFolder(root=f'{DATA_DIR}/train', transform=transform_train)\n",
        "val_dataset = datasets.ImageFolder(root=f'{DATA_DIR}/test', transform=transform_val)\n",
        "\n",
        "# Data Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1hpuTxnote2"
      },
      "outputs": [],
      "source": [
        "class InceptionResNetV2ViT(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES):\n",
        "        super(InceptionResNetV2ViT, self).__init__()\n",
        "\n",
        "        # Load pre-trained InceptionResNetV2\n",
        "        self.inception_resnet = create_model('inception_resnet_v2', pretrained=True)\n",
        "\n",
        "        # Define feature extractor by inspecting InceptionResNetV2 layers\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            self.inception_resnet.conv2d_1a,\n",
        "            self.inception_resnet.conv2d_2a,\n",
        "            self.inception_resnet.conv2d_2b,\n",
        "            self.inception_resnet.maxpool_3a,\n",
        "            self.inception_resnet.conv2d_3b,\n",
        "            self.inception_resnet.conv2d_4a,\n",
        "            self.inception_resnet.maxpool_5a,\n",
        "            self.inception_resnet.mixed_5b,\n",
        "            self.inception_resnet.repeat,\n",
        "            self.inception_resnet.mixed_6a,\n",
        "            self.inception_resnet.repeat_1,\n",
        "            self.inception_resnet.mixed_7a,\n",
        "            self.inception_resnet.repeat_2,\n",
        "            self.inception_resnet.block8,\n",
        "            self.inception_resnet.conv2d_7b,\n",
        "        )\n",
        "\n",
        "        # Vision Transformer configuration\n",
        "        self.vit_config = ViTConfig(\n",
        "            hidden_size=1536,  # Output from InceptionResNetV2\n",
        "            num_attention_heads=8,  # Number of attention heads\n",
        "            num_hidden_layers=6,  # Number of transformer layers\n",
        "            intermediate_size=3072,  # Intermediate size in the transformer\n",
        "            patch_size=1, # Adjust patch size to match the feature map dimensions\n",
        "            image_size=5  # Assuming the feature map size is 7x7 after InceptionResNetV2 with a patch size of 8\n",
        "        )\n",
        "        self.transformer = ViTModel(self.vit_config)\n",
        "\n",
        "        # Adaptor layer to match the number of channels\n",
        "        self.channel_adaptor = nn.Conv2d(1536, 3, kernel_size=1)  # 1x1 convolution to reduce channels\n",
        "\n",
        "        # Output classification head\n",
        "        self.fc = nn.Linear(self.vit_config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)  # This should now have the expected shape [batch_size, 1536, h, w]\n",
        "\n",
        "        # Adapt the number of channels to match ViT input\n",
        "        features = self.channel_adaptor(features)\n",
        "\n",
        "        # Pass through Transformer encoder\n",
        "        # Use 'pixel_values' for newer versions of transformers\n",
        "        transformer_outputs = self.transformer(pixel_values=features)\n",
        "        transformer_features = transformer_outputs.last_hidden_state  # Shape: [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        # Classification head\n",
        "        pooled_output = transformer_features.mean(dim=1)  # Global average pooling\n",
        "        logits = self.fc(pooled_output)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXx0Wu_Iozee",
        "outputId": "20eea471-a74f-4bbc-aef7-27f4444c5573"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "model = InceptionResNetV2ViT(num_classes=NUM_CLASSES)\n",
        "model = model.cuda()  # Move to GPU if available\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training and Validation Loop\n",
        "train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss, running_corrects = 0.0, 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda() # Move inputs and labels to GPU\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_acc.item())\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss, val_running_corrects = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda() # Move inputs and labels to GPU - This was missing\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    val_loss = val_running_loss / len(val_loader.dataset)\n",
        "    val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Test Loss: {val_loss:.4f}, Test Acc: {val_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Plotting Histograms\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.title('Train Loss and Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_losses, label='Test Loss')\n",
        "plt.plot(val_accuracies, label='Test Accuracy')\n",
        "plt.title('Test Loss and Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix and Inference Time\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n",
        "\n",
        "# Test and Inference Time\n",
        "test_dataset = datasets.ImageFolder(root=f'{DATA_DIR}/test', transform=transform_val)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "model.eval()\n",
        "test_running_loss, test_running_corrects, inference_times = 0.0, 0, []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        start_time = time.time()\n",
        "        outputs = model(inputs)\n",
        "        inference_time = time.time() - start_time\n",
        "        inference_times.append(inference_time)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_loss = test_running_loss / len(test_loader.dataset)\n",
        "test_acc = test_running_corrects.double() / len(test_loader.dataset)\n",
        "avg_inference_time = sum(inference_times) / len(inference_times)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Average Inference Time per Batch: {avg_inference_time:.4f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
